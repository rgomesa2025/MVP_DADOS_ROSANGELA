{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc69d042-6ce8-4753-b4da-d409bf52bde4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### MVP - Construção de um pipeline de dados\n",
    "\n",
    "  A pipeline consistem em cinco etapas bem definidas, como buscar, coletar, modelar, carregar e análisar os dados.\n",
    "\n",
    "  Na primeira etapa que é a busca dos dados, foi escolhido dados abertos na web no site Portal da Transparencia do governo federal [https://portaldatransparencia.gov.br/].\n",
    "\n",
    "  Dentre as inumeras bases de dados no site, a escolhida foram os dados dos aposentados do Banco Central do Brasil (BACEN) que encontram-se ativos.  \n",
    "  O período de análise será de Janeiro de 2025 até Setembro de 2025.\n",
    "\n",
    "  A proposta é conseguir responder as seguintes perguntas com a massa de dados escolhida:\n",
    "  - Qual a faixa etária dos servidores?\n",
    "  - Qual é a média de idade desses servidores?   \n",
    "  - Quantos desses servidores estão ocupando cargos de alta gestão ou função comissionada? \n",
    "  - Qual foi o fluxo de aposentados na ativa no período? \n",
    "  - Quantos aposentados foram reativados a cada mês? \n",
    "  - Em quais departamentos a concentração de aposentados na ativa é maior? \n",
    "\n",
    "  A segunda etapa consistem em coletar esses dados do site e importar ele dentro da ferramaneta databricks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcdcd234-fd46-4c35-8c7f-dfb2d3051e31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.empty-table+json": {
       "directive_name": "NoDirective"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%sql\n",
    "\n",
    "-- Cria o catálogo principal para todos os seus dados do BACEN\n",
    "CREATE CATALOG IF NOT EXISTS catalog_bacen\n",
    "COMMENT 'Catálogo para dados públicos dos Servidores Aposentados Ativos do Banco do Brasil (BACEN).';\n",
    "\n",
    "-- Opcional: Crie os esquemas (databases) Bronze, Silver e Gold dentro do novo catálogo\n",
    "CREATE SCHEMA IF NOT EXISTS catalog_bacen.bronze;\n",
    "CREATE SCHEMA IF NOT EXISTS catalog_bacen.silver;\n",
    "CREATE SCHEMA IF NOT EXISTS catalog_bacen.gold;\n",
    "\n",
    "-- 1. Criação do Volume para armazenar os arquivos\n",
    "-- Assumimos o nome 'dados_servidores' para o Volume que armazenará seus arquivos.\n",
    "CREATE VOLUME IF NOT EXISTS catalog_bacen.bronze.dados_servidores\n",
    "COMMENT 'Volume para arquivos CSV brutos dos Servidores Aposentados Ativos do Banco do Brasil (BACEN).';\n",
    "\n",
    "-- 2. Criação do Volume para armazenar as tabelas \n",
    "-- Assumimos o nome 'dados_servidores' para o Volume que armazenará suas tabelas.\n",
    "CREATE VOLUME IF NOT EXISTS catalog_bacen.silver.dados_servidores\n",
    "COMMENT 'Volume para armazenar as tabelas dos Servidores Aposentados Ativos do Banco do Brasil (BACEN).';\n",
    "\n",
    "-- 2. Criação do Volume para armazenar o modelo estrela\n",
    "-- Assumimos o nome 'dados_servidores' para o Volume que armazenará o modelo estrela.\n",
    "CREATE VOLUME IF NOT EXISTS catalog_bacen.gold.dados_servidores\n",
    "COMMENT 'Volume para armazenar o modelo estrela dos Servidores Aposentados Ativos do Banco do Brasil (BACEN).';\n",
    "\n",
    "-- Define o catálogo recém-criado como o padrão para as próximas operações\n",
    "USE CATALOG catalog_bacen;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e38ac61-8812-416c-b19b-c502106b59ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unidecode\n  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\nDownloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\nInstalling collected packages: unidecode\nSuccessfully installed unidecode-1.4.0\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# Tente rodar esta linha em uma célula separada antes do código principal\n",
    "%pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb915c76-ea07-4773-9afd-8ce4d7df99af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando processamento para os meses: ['202501', '202502', '202503', '202504', '202505', '202506', '202507', '202508', '202509']\n\n==================================================\nPROCESSANDO COMPETÊNCIA: 202501\n==================================================\n -> Baixando: https://portaldatransparencia.gov.br/download-de-dados/servidores/202501_Aposentados_BACEN/\n    -> Lendo CSV: 202501_Remuneracao.csv\nWrote 1722463 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202501_Remuneracao_delta\n    -> Lendo CSV: 202501_Observacoes.csv\nWrote 59 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202501_Observacoes_delta\n    -> Lendo CSV: 202501_Cadastro.csv\nWrote 1779125 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202501_Cadastro_delta\n -> Concluído com sucesso para 202501\n\n==================================================\nPROCESSANDO COMPETÊNCIA: 202502\n==================================================\n -> Baixando: https://portaldatransparencia.gov.br/download-de-dados/servidores/202502_Aposentados_BACEN/\n    -> Lendo CSV: 202502_Cadastro.csv\nWrote 1777220 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202502_Cadastro_delta\n    -> Lendo CSV: 202502_Remuneracao.csv\nWrote 1720778 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202502_Remuneracao_delta\n    -> Lendo CSV: 202502_Observacoes.csv\nWrote 59 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202502_Observacoes_delta\n -> Concluído com sucesso para 202502\n\n==================================================\nPROCESSANDO COMPETÊNCIA: 202503\n==================================================\n -> Baixando: https://portaldatransparencia.gov.br/download-de-dados/servidores/202503_Aposentados_BACEN/\n    -> Lendo CSV: 202503_Observacoes.csv\nWrote 59 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202503_Observacoes_delta\n    -> Lendo CSV: 202503_Remuneracao.csv\nWrote 1720047 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202503_Remuneracao_delta\n    -> Lendo CSV: 202503_Cadastro.csv\nWrote 6867003 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202503_Cadastro_delta\n -> Concluído com sucesso para 202503\n\n==================================================\nPROCESSANDO COMPETÊNCIA: 202504\n==================================================\n -> Baixando: https://portaldatransparencia.gov.br/download-de-dados/servidores/202504_Aposentados_BACEN/\n    -> Lendo CSV: 202504_Observacoes.csv\nWrote 59 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202504_Observacoes_delta\n    -> Lendo CSV: 202504_Cadastro.csv\nWrote 6867235 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202504_Cadastro_delta\n    -> Lendo CSV: 202504_Remuneracao.csv\nWrote 1757014 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202504_Remuneracao_delta\n -> Concluído com sucesso para 202504\n\n==================================================\nPROCESSANDO COMPETÊNCIA: 202505\n==================================================\n -> Baixando: https://portaldatransparencia.gov.br/download-de-dados/servidores/202505_Aposentados_BACEN/\n    -> Lendo CSV: 202505_Cadastro.csv\nWrote 1918853 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202505_Cadastro_delta\n    -> Lendo CSV: 202505_Remuneracao.csv\nWrote 1722019 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202505_Remuneracao_delta\n    -> Lendo CSV: 202505_Observacoes.csv\nWrote 59 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202505_Observacoes_delta\n -> Concluído com sucesso para 202505\n\n==================================================\nPROCESSANDO COMPETÊNCIA: 202506\n==================================================\n -> Baixando: https://portaldatransparencia.gov.br/download-de-dados/servidores/202506_Aposentados_BACEN/\n    -> Lendo CSV: 202506_Remuneracao.csv\nWrote 1719758 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202506_Remuneracao_delta\n    -> Lendo CSV: 202506_Observacoes.csv\nWrote 59 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202506_Observacoes_delta\n    -> Lendo CSV: 202506_Cadastro.csv\nWrote 1916333 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202506_Cadastro_delta\n -> Concluído com sucesso para 202506\n\n==================================================\nPROCESSANDO COMPETÊNCIA: 202507\n==================================================\n -> Baixando: https://portaldatransparencia.gov.br/download-de-dados/servidores/202507_Aposentados_BACEN/\n    -> Lendo CSV: 202507_Cadastro.csv\nWrote 1915957 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202507_Cadastro_delta\n    -> Lendo CSV: 202507_Remuneracao.csv\nWrote 1719340 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202507_Remuneracao_delta\n    -> Lendo CSV: 202507_Observacoes.csv\nWrote 59 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202507_Observacoes_delta\n -> Concluído com sucesso para 202507\n\n==================================================\nPROCESSANDO COMPETÊNCIA: 202508\n==================================================\n -> Baixando: https://portaldatransparencia.gov.br/download-de-dados/servidores/202508_Aposentados_BACEN/\n    -> Lendo CSV: 202508_Remuneracao.csv\nWrote 1719621 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202508_Remuneracao_delta\n    -> Lendo CSV: 202508_Observacoes.csv\nWrote 59 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202508_Observacoes_delta\n    -> Lendo CSV: 202508_Cadastro.csv\nWrote 1915963 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202508_Cadastro_delta\n -> Concluído com sucesso para 202508\n\n==================================================\nPROCESSANDO COMPETÊNCIA: 202509\n==================================================\n -> Baixando: https://portaldatransparencia.gov.br/download-de-dados/servidores/202509_Aposentados_BACEN/\n    -> Lendo CSV: 202509_Cadastro.csv\nWrote 1914508 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202509_Cadastro_delta\n    -> Lendo CSV: 202509_Observacoes.csv\nWrote 59 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202509_Observacoes_delta\n    -> Lendo CSV: 202509_Remuneracao.csv\nWrote 1718299 bytes.\n    -> Sucesso: /Volumes/catalog_bacen/bronze/dados_servidores/202509_Remuneracao_delta\n -> Concluído com sucesso para 202509\n\nPipeline finalizado para todos os meses disponíveis.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import re\n",
    "from unidecode import unidecode \n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# --- CONFIGURAÇÃO DE CAMINHOS ---\n",
    "UC_VOLUME_PATH = \"/Volumes/catalog_bacen/bronze/dados_servidores/\"\n",
    "\n",
    "# --- FUNÇÃO DE LIMPEZA (MANTIDA) ---\n",
    "def limpar_nome_coluna(nome_coluna):\n",
    "    nome_limpo = unidecode(nome_coluna) \n",
    "    nome_limpo = re.sub(r' \\(R\\$\\)(\\(\\*\\))?$', '_REAIS', nome_limpo)\n",
    "    nome_limpo = re.sub(r' \\(U\\$\\)(\\(\\*\\))?$', '_DOLAR', nome_limpo)\n",
    "    nome_limpo = re.sub(r'[/,;{}\\(\\)\\n\\t\\=–]', ' ', nome_limpo)\n",
    "    nome_limpo = nome_limpo.strip().lower() \n",
    "    nome_limpo = re.sub(r'\\s+', '_', nome_limpo)\n",
    "    nome_limpo = nome_limpo.strip('_')\n",
    "    nome_limpo = re.sub(r'__+', '_', nome_limpo)\n",
    "    return nome_limpo\n",
    "\n",
    "# --- LOOP PARA OS MESES (JANEIRO A SETEMBRO) ---\n",
    "# Geramos uma lista de meses formatados: ['202501', '202502', ..., '202509']\n",
    "meses_para_processar = [f\"2025{str(mes).zfill(2)}\" for mes in range(1, 10)]\n",
    "\n",
    "print(f\"Iniciando processamento para os meses: {meses_para_processar}\")\n",
    "\n",
    "for competencia in meses_para_processar:\n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    print(f\"PROCESSANDO COMPETÊNCIA: {competencia}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Dinamiza as variáveis com base no mês\n",
    "    ZIP_URL = f\"https://portaldatransparencia.gov.br/download-de-dados/servidores/{competencia}_Aposentados_BACEN/\"\n",
    "    ZIP_FILENAME = f\"{competencia}_Aposentados_BACEN.zip\"\n",
    "    TEMP_DOWNLOAD_PATH = f\"/tmp/{ZIP_FILENAME}\"\n",
    "    TEMP_UNZIP_DIR = f\"/tmp/unzip_{competencia}\"\n",
    "\n",
    "    try:\n",
    "        # A. DOWNLOAD\n",
    "        print(f\" -> Baixando: {ZIP_URL}\")\n",
    "        response = requests.get(ZIP_URL, stream=True)\n",
    "        \n",
    "        if response.status_code == 404:\n",
    "            print(f\" [AVISO] Dados para {competencia} não encontrados (404). Pulando...\")\n",
    "            continue\n",
    "            \n",
    "        response.raise_for_status()\n",
    "        \n",
    "        with open(TEMP_DOWNLOAD_PATH, \"wb\") as file:\n",
    "            for chunk in response.iter_content(chunk_size=1024 * 1024):\n",
    "                file.write(chunk)\n",
    "                \n",
    "        # B. DESCOMPACTAR\n",
    "        os.makedirs(TEMP_UNZIP_DIR, exist_ok=True)\n",
    "        with ZipFile(TEMP_DOWNLOAD_PATH, 'r') as zip_ref:\n",
    "            zip_ref.extractall(TEMP_UNZIP_DIR)\n",
    "        \n",
    "        # C. PROCESSAR ARQUIVOS\n",
    "        for filename in os.listdir(TEMP_UNZIP_DIR):\n",
    "            if filename.lower().endswith('.csv'):\n",
    "                local_csv_path = os.path.join(TEMP_UNZIP_DIR, filename)\n",
    "                remote_delta_path = UC_VOLUME_PATH + filename.replace(\".csv\", \"\") + \"_delta\"\n",
    "                \n",
    "                print(f\"    -> Lendo CSV: {filename}\")\n",
    "                \n",
    "                # Lendo com tratamento de encoding\n",
    "                with open(local_csv_path, 'r', encoding='ISO-8859-1') as f:\n",
    "                    csv_content = f.read()\n",
    "\n",
    "                temp_csv_file_on_volume = f\"{UC_VOLUME_PATH}temp_{competencia}_{filename}\"\n",
    "                dbutils.fs.put(temp_csv_file_on_volume, csv_content, overwrite=True)\n",
    "                \n",
    "                # Spark Read\n",
    "                df_temp = (spark.read \n",
    "                           .format(\"csv\") \n",
    "                           .option(\"header\", \"true\") \n",
    "                           .option(\"delimiter\", \";\") \n",
    "                           .option(\"encoding\", \"ISO-8859-1\") \n",
    "                           .load(temp_csv_file_on_volume)\n",
    "                          )\n",
    "                \n",
    "                # Renomear Colunas\n",
    "                mapeamento = {c: limpar_nome_coluna(c) for c in df_temp.columns}\n",
    "                df_limpo = df_temp\n",
    "                for old_name, new_name in mapeamento.items():\n",
    "                    df_limpo = df_limpo.withColumnRenamed(old_name, new_name)\n",
    "                \n",
    "                # Salvar Delta\n",
    "                df_limpo.write.format(\"delta\").mode(\"overwrite\").save(remote_delta_path)\n",
    "                dbutils.fs.rm(temp_csv_file_on_volume)\n",
    "                print(f\"    -> Sucesso: {remote_delta_path}\")\n",
    "\n",
    "        # D. LIMPEZA TEMPORÁRIA (por mês)\n",
    "        os.remove(TEMP_DOWNLOAD_PATH) \n",
    "        shutil.rmtree(TEMP_UNZIP_DIR)\n",
    "        print(f\" -> Concluído com sucesso para {competencia}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" [ERRO] Falha ao processar {competencia}: {e}\")\n",
    "        # Continua para o próximo mês mesmo se um falhar\n",
    "        continue\n",
    "\n",
    "print(\"\\nPipeline finalizado para todos os meses disponíveis.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6574085027863048,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "MVP",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
